#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡æ¨ç†ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼çš„æ‰¹é‡æ¨ç†åŠŸèƒ½æ¥ç”Ÿæˆæ•°æ®é›†ï¼Œæˆæœ¬ä»…ä¸ºå®æ—¶æ¨ç†çš„50%
"""

import os
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from batch_inference import BatchInferenceManager, QianWenBatchInference
from data import QianWenDataGenerator


async def example_basic_batch_inference():
    """åŸºæœ¬æ‰¹é‡æ¨ç†ç¤ºä¾‹"""
    print("=== åŸºæœ¬æ‰¹é‡æ¨ç†ç¤ºä¾‹ ===")
    
    # è·å–APIå¯†é’¥
    api_key = os.getenv('QIANWEN_API_KEY') or os.getenv('DASHSCOPE_API_KEY')
    if not api_key:
        print("é”™è¯¯: è¯·è®¾ç½®ç¯å¢ƒå˜é‡ QIANWEN_API_KEY æˆ– DASHSCOPE_API_KEY")
        return
    
    # åˆ›å»ºæµ‹è¯•æç¤º
    prompts = [
        "è¯·ç®€å•è§£é‡Šä¸€ä¸‹é‡å­å åŠ åŸç†",
        "ä»€ä¹ˆæ˜¯é‡å­çº ç¼ ï¼Ÿè¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Š",
        "Shorç®—æ³•æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ",
        "é‡å­è®¡ç®—ä¸ç»å…¸è®¡ç®—çš„ä¸»è¦åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ"
    ]
    
    # åˆ›å»ºæ‰¹é‡æ¨ç†ç®¡ç†å™¨
    manager = BatchInferenceManager(api_key, model='qwen-plus')
    
    try:
        # è¿è¡Œæ‰¹é‡æ¨ç†
        result = await manager.run_batch_inference(
            prompts=prompts,
            job_name="basic_example",
            completion_window="24h",
            wait_for_completion=True,  # ç­‰å¾…å®Œæˆ
            temperature=0.7,
            max_tokens=1000
        )
        
        print(f"æ‰¹é‡ä»»åŠ¡å®Œæˆ: {result['job_id']}")
        print(f"çŠ¶æ€: {result['status']}")
        print(f"ç»“æœæ•°é‡: {len(result.get('results', []))}")
        
        return result
        
    except Exception as e:
        print(f"æ‰¹é‡æ¨ç†å¤±è´¥: {e}")
        return None


async def example_dataset_generation_with_batch():
    """ä½¿ç”¨æ‰¹é‡æ¨ç†ç”Ÿæˆæ•°æ®é›†çš„ç¤ºä¾‹"""
    print("\n=== æ•°æ®é›†æ‰¹é‡ç”Ÿæˆç¤ºä¾‹ ===")
    
    # è·å–APIå¯†é’¥
    api_key = os.getenv('QIANWEN_API_KEY') or os.getenv('DASHSCOPE_API_KEY')
    if not api_key:
        print("é”™è¯¯: è¯·è®¾ç½®ç¯å¢ƒå˜é‡")
        return
    
    # ä½¿ç”¨æ•°æ®ç”Ÿæˆå™¨çš„æ‰¹é‡æ¨¡å¼
    async with QianWenDataGenerator(api_key, model='qwen-plus') as generator:
        await generator.generate_dataset_from_papers(
            output_file="batch_example_dataset.jsonl",
            max_samples_per_paper=2,  # æ¯ç¯‡è®ºæ–‡2ä¸ªæ ·æœ¬
            use_batch=True,  # å¯ç”¨æ‰¹é‡æ¨ç†
            batch_completion_window="24h"
        )
    
    print("æ•°æ®é›†æ‰¹é‡ç”Ÿæˆå®Œæˆ!")


async def example_batch_job_management():
    """æ‰¹é‡ä»»åŠ¡ç®¡ç†ç¤ºä¾‹"""
    print("\n=== æ‰¹é‡ä»»åŠ¡ç®¡ç†ç¤ºä¾‹ ===")
    
    api_key = os.getenv('QIANWEN_API_KEY') or os.getenv('DASHSCOPE_API_KEY')
    if not api_key:
        print("é”™è¯¯: è¯·è®¾ç½®ç¯å¢ƒå˜é‡")
        return
    
    client = QianWenBatchInference(api_key, model='qwen-plus')
    
    try:
        # åˆ—å‡ºæ‰€æœ‰æ‰¹é‡ä»»åŠ¡
        jobs = client.list_batch_jobs(limit=5)
        print(f"æ‰¾åˆ° {len(jobs)} ä¸ªæ‰¹é‡ä»»åŠ¡:")
        
        for job in jobs:
            print(f"  - ID: {job.id}")
            print(f"    çŠ¶æ€: {job.status.value}")
            print(f"    åˆ›å»ºæ—¶é—´: {job.created_at}")
            if job.completed_at:
                print(f"    å®Œæˆæ—¶é—´: {job.completed_at}")
            print()
            
    except Exception as e:
        print(f"è·å–æ‰¹é‡ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")


def example_cli_usage():
    """CLIä½¿ç”¨ç¤ºä¾‹"""
    print("\n=== CLIä½¿ç”¨ç¤ºä¾‹ ===")
    
    print("1. åˆ›å»ºæ‰¹é‡ä»»åŠ¡:")
    print("   python batch_cli.py create --prompt 'è§£é‡Šé‡å­è®¡ç®—åŸç†' --job-name test --wait")
    print()
    
    print("2. ä»æ–‡ä»¶åˆ›å»ºæ‰¹é‡ä»»åŠ¡:")
    print("   python batch_cli.py create --input-file prompts.txt --job-name my_batch")
    print()
    
    print("3. æ£€æŸ¥ä»»åŠ¡çŠ¶æ€:")
    print("   python batch_cli.py status batch_12345")
    print()
    
    print("4. åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡:")
    print("   python batch_cli.py list")
    print()
    
    print("5. å–æ¶ˆä»»åŠ¡:")
    print("   python batch_cli.py cancel batch_12345")


def show_cost_comparison():
    """æ˜¾ç¤ºæˆæœ¬å¯¹æ¯”"""
    print("\n=== æˆæœ¬å¯¹æ¯” ===")
    print("å‡è®¾å¤„ç†1000ä¸ªè¯·æ±‚ï¼š")
    print("â€¢ å®æ—¶æ¨ç†æˆæœ¬: 100% (åŸºå‡†)")
    print("â€¢ æ‰¹é‡æ¨ç†æˆæœ¬: 50% (èŠ‚çœ50%)")
    print("â€¢ èŠ‚çœé‡‘é¢: å¦‚æœå®æ—¶æˆæœ¬ä¸º100å…ƒï¼Œæ‰¹é‡æ¨ç†ä»…éœ€50å…ƒ")
    print("\næ‰¹é‡æ¨ç†ç‰¹ç‚¹:")
    print("â€¢ âœ… æˆæœ¬é™ä½50%")
    print("â€¢ âœ… é€‚åˆå¤§è§„æ¨¡æ•°æ®å¤„ç†")
    print("â€¢ âœ… æ”¯æŒç¦»çº¿å¤„ç†")
    print("â€¢ â° éœ€è¦ç­‰å¾…æ—¶é—´(24h-336h)")
    print("â€¢ ğŸ“Š æœ€é€‚åˆéç´§æ€¥çš„å¤§æ‰¹é‡ä»»åŠ¡")


async def main():
    """ä¸»å‡½æ•°"""
    print("é˜¿é‡Œäº‘ç™¾ç‚¼æ‰¹é‡æ¨ç†ä½¿ç”¨ç¤ºä¾‹")
    print("="*50)
    
    # æ˜¾ç¤ºæˆæœ¬å¯¹æ¯”
    show_cost_comparison()
    
    # åŸºæœ¬æ‰¹é‡æ¨ç†ç¤ºä¾‹
    result = await example_basic_batch_inference()
    
    # å¦‚æœç”¨æˆ·ç¡®è®¤ï¼Œè¿è¡Œæ•°æ®é›†ç”Ÿæˆç¤ºä¾‹
    if result:
        user_input = input("\næ˜¯å¦è¿è¡Œæ•°æ®é›†æ‰¹é‡ç”Ÿæˆç¤ºä¾‹? (y/N): ")
        if user_input.lower() in ['y', 'yes']:
            await example_dataset_generation_with_batch()
    
    # æ‰¹é‡ä»»åŠ¡ç®¡ç†ç¤ºä¾‹
    await example_batch_job_management()
    
    # CLIä½¿ç”¨ç¤ºä¾‹
    example_cli_usage()
    
    print("\nç¤ºä¾‹æ¼”ç¤ºå®Œæˆ!")
    print("è¦å¼€å§‹ä½¿ç”¨æ‰¹é‡æ¨ç†ï¼Œè¯·:")
    print("1. è®¾ç½®APIå¯†é’¥: export DASHSCOPE_API_KEY='your-key'")
    print("2. è¿è¡Œ: python data.py --batch --completion-window 24h")
    print("3. æˆ–ä½¿ç”¨CLI: python batch_cli.py create --input-file prompts.txt")


if __name__ == "__main__":
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    Path("batch_jobs").mkdir(exist_ok=True)
    
    # è¿è¡Œç¤ºä¾‹
    asyncio.run(main())